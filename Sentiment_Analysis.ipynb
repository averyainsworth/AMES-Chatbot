{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoSYeDfkRbOj",
        "outputId": "da019b88-0826-44ab-9367-1001961e5cf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: pickle5 in /usr/local/lib/python3.10/dist-packages (0.0.11)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.57.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.14)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.7.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.33.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.7)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "! pip install tensorflow scikit-learn pandas numpy pickle5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqEo45UtBSem",
        "outputId": "2f81ec06-b029-40e9-9fe6-809309e01585"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Y1w8C_leLydJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "2dGkxpO_ZtcT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, LSTM, SimpleRNN, Bidirectional\n",
        "import pickle5 as pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jp67pAq3HXMX"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "jlJ4DpZmZ3nr"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/tweet_emotions.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceoiQACJaSXg",
        "outputId": "2e234997-a6a4-4e4a-9a01-f492f532a2b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     tweet_id   sentiment                                            content\n",
            "0  1956967341       empty  @tiffanylue i know  i was listenin to bad habi...\n",
            "1  1956967666     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
            "2  1956967696     sadness                Funeral ceremony...gloomy friday...\n",
            "3  1956967789  enthusiasm               wants to hang out with friends SOON!\n",
            "4  1956968416     neutral  @dannycastillo We want to trade with someone w...\n"
          ]
        }
      ],
      "source": [
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "znbyhUCJaXtO"
      },
      "outputs": [],
      "source": [
        "df = df[['sentiment', 'content']]\n",
        "df = df.sample(frac=1).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "6vOXGiXQahkz"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words=5000, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(df['content'])\n",
        "word_index = tokenizer.word_index\n",
        "sequences = tokenizer.texts_to_sequences(df['content'])\n",
        "padded_sequences = pad_sequences(sequences, maxlen=100, truncating='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "vI3cCOmgazQ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96ecba24-72b8-4518-95fa-8291cb3cf0df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       anger  boredom  empty  enthusiasm  fun  happiness  hate  love  neutral  \\\n",
            "0          0        0      0           0    0          1     0     0        0   \n",
            "1          0        0      0           0    0          0     0     1        0   \n",
            "2          0        0      0           0    0          0     0     0        0   \n",
            "3          0        0      0           0    0          0     0     0        0   \n",
            "4          0        0      0           0    0          0     0     0        0   \n",
            "...      ...      ...    ...         ...  ...        ...   ...   ...      ...   \n",
            "39995      0        0      0           0    0          0     0     0        0   \n",
            "39996      0        0      1           0    0          0     0     0        0   \n",
            "39997      0        0      0           0    0          0     0     0        0   \n",
            "39998      0        0      0           0    0          0     0     0        0   \n",
            "39999      0        0      0           0    0          0     0     1        0   \n",
            "\n",
            "       relief  sadness  surprise  worry  \n",
            "0           0        0         0      0  \n",
            "1           0        0         0      0  \n",
            "2           0        1         0      0  \n",
            "3           0        0         0      1  \n",
            "4           0        1         0      0  \n",
            "...       ...      ...       ...    ...  \n",
            "39995       0        1         0      0  \n",
            "39996       0        0         0      0  \n",
            "39997       0        0         0      1  \n",
            "39998       0        0         0      1  \n",
            "39999       0        0         0      0  \n",
            "\n",
            "[40000 rows x 13 columns]\n"
          ]
        }
      ],
      "source": [
        "sentiment_labels = pd.get_dummies(df['sentiment']).values\n",
        "print(pd.get_dummies(df['sentiment']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "ahlRxL-Ya2KW"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(padded_sequences, sentiment_labels, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0xCs606a5-l",
        "outputId": "038235bc-3176-421e-f717-eec136fc04bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 100, 100)          500000    \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 96, 64)            32064     \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 64)               0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 13)                429       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 534,573\n",
            "Trainable params: 534,573\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(5000, 100, input_length=100))\n",
        "model.add(Conv1D(64, 5, activation='relu'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(13, activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mW78ocpdewpd",
        "outputId": "8692d042-c858-4cec-99b5-73d4cef3d28f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 100, 100)          500000    \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 100, 100)          20100     \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 100)               20100     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 13)                1313      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 541,513\n",
            "Trainable params: 541,513\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(5000, 100, input_length=100))\n",
        "model.add(SimpleRNN(100, return_sequences=True))\n",
        "model.add(SimpleRNN(100))\n",
        "model.add(Dense(13, activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqYZbzmRhS0W",
        "outputId": "01f05096-5ed0-4b01-ba1c-3af0eaa9605c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 100, 100)          500000    \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 400)              481600    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 13)                5213      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 986,813\n",
            "Trainable params: 986,813\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(5000, 100, input_length=100))\n",
        "model.add(Bidirectional(LSTM(200, activation = 'relu')))\n",
        "model.add(Dense(13, activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwRjWOLva9AT",
        "outputId": "a06e95a2-8872-4552-ce9b-c29684161d2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1000/1000 [==============================] - 553s 551ms/step - loss: 792524.6250 - accuracy: 0.2197 - val_loss: 2.1278 - val_accuracy: 0.2550\n",
            "Epoch 2/3\n",
            "1000/1000 [==============================] - 541s 541ms/step - loss: 2.3479 - accuracy: 0.2682 - val_loss: 2.0598 - val_accuracy: 0.2784\n",
            "Epoch 3/3\n",
            "1000/1000 [==============================] - 540s 540ms/step - loss: 1.9996 - accuracy: 0.3080 - val_loss: 1.9865 - val_accuracy: 0.3194\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7a528c9698d0>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "model.fit(x_train, y_train, epochs=3, batch_size=32, validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rVe2IMfbAae",
        "outputId": "28611697-8b4a-4036-ea91-bd36557abf60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "250/250 [==============================] - 62s 247ms/step\n",
            "Accuracy: 0.319375\n"
          ]
        }
      ],
      "source": [
        "y_pred = np.argmax(model.predict(x_test), axis=-1)\n",
        "print(\"Accuracy:\", accuracy_score(np.argmax(y_test, axis=-1), y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "AEdLHnq3bC6a"
      },
      "outputs": [],
      "source": [
        "model.save('sentiment_analysis_model.h5')\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "88Cl-aCv_ZsV"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "\n",
        "model = keras.models.load_model('sentiment_analysis_model.h5')\n",
        "with open('tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import random\n",
        "import string\n",
        "import warnings\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "oXLRv8T3L8re"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGVjMhr0L-or",
        "outputId": "997c45a5-7d84-4870-eaec-0b6a88f1ea44"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('popular', quiet=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Sk6Iq8NMAoF",
        "outputId": "de78c3de-24d2-4190-fcae-c3c0948d8fe4"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f=open('/content/drive/MyDrive/Chatbot.txt','r',errors = 'ignore')\n",
        "raw=f.read()\n",
        "raw = raw.lower()"
      ],
      "metadata": {
        "id": "AOl2xkJiMFwQ"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokens = nltk.sent_tokenize(raw)\n",
        "word_tokens = nltk.word_tokenize(raw)"
      ],
      "metadata": {
        "id": "gG7g3OkZMGTP"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmer = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "def LemTokens(tokens):\n",
        "    return [lemmer.lemmatize(token) for token in tokens]\n",
        "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
        "\n",
        "def LemNormalize(text):\n",
        "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
      ],
      "metadata": {
        "id": "gk9B4uJ2MIGp"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",)\n",
        "GREETING_RESPONSES = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\n",
        "def greeting(sentence):\n",
        "\n",
        "    for word in sentence.split():\n",
        "        if word.lower() in GREETING_INPUTS:\n",
        "            return random.choice(GREETING_RESPONSES)"
      ],
      "metadata": {
        "id": "sSpQSb1fMMCH"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def response(user_response):\n",
        "    robo_response=''\n",
        "    sent_tokens.append(user_response)\n",
        "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
        "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
        "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
        "    idx=vals.argsort()[0][-2]\n",
        "    flat = vals.flatten()\n",
        "    flat.sort()\n",
        "    req_tfidf = flat[-2]\n",
        "    if(req_tfidf==0):\n",
        "        robo_response=robo_response+\"I am sorry! I don't understand you\"\n",
        "        return robo_response\n",
        "    else:\n",
        "        robo_response = robo_response+sent_tokens[idx]\n",
        "        return robo_response"
      ],
      "metadata": {
        "id": "qD8WK9ukMOpB"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "question_list = [\"How are you feeling?\", \"How have you been?\", \"Is something worrying you?\", \"Are you having trouble sleeping? If so, why?\", \"Is there anything you want to talk about?\", \"How would you like things to be different?\", \"Did something upset you today?\", \"Is someone bothering you?\"]\n",
        "\n",
        "\n",
        "randomQuestion = random.choice(question_list)\n",
        "question_list.remove(randomQuestion)\n",
        "randomQuestion2 = random.choice(question_list)\n",
        "question_list.remove(randomQuestion2)\n",
        "randomQuestion3 = random.choice(question_list)\n",
        "question_list.remove(randomQuestion3)"
      ],
      "metadata": {
        "id": "JV67hP0_gFL9"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flag=True\n",
        "\n",
        "\n",
        "while(flag == True):\n",
        "\n",
        "  print(\"AMES: My name is AMES. I will be asking you a few questions about how you are feeling. If you want to exit, type Bye!\")\n",
        "\n",
        "\n",
        "  print(randomQuestion)\n",
        "  user_response = input()\n",
        "  text_sequence = tokenizer.texts_to_sequences([user_response])\n",
        "  text_sequence = pad_sequences(text_sequence, maxlen=100)\n",
        "\n",
        "  sentiment = model.predict(text_sequence)\n",
        "\n",
        "  # Using numpy.array.argmax()\n",
        "  max_index= np.array(sentiment).argmax()\n",
        "\n",
        "  real_sentiment1 = \"any\"\n",
        "\n",
        "\n",
        "  if(max_index==0):\n",
        "    real_sentiment1= \"anger\"\n",
        "  elif(max_index==1):\n",
        "    real_sentiment1= \"boredom\"\n",
        "  elif(max_index==2):\n",
        "    real_sentiment1 = \"empty\"\n",
        "  elif(max_index==3):\n",
        "    real_sentiment1 = \"enthusiasm\"\n",
        "  elif(max_index==4):\n",
        "    real_sentiment1= \"fun\"\n",
        "  elif(max_index==5):\n",
        "    real_sentiment1 = \"happiness\"\n",
        "  elif(max_index==6):\n",
        "    real_sentiment1= \"hate\"\n",
        "  elif(max_index==7):\n",
        "    real_sentiment1 = \"love\"\n",
        "  elif(max_index==8):\n",
        "    real_sentiment1= \"neutral\"\n",
        "  elif(max_index==9):\n",
        "    real_sentiment1 = \"relief\"\n",
        "  elif(max_index==10):\n",
        "    real_sentiment1= \"sadness\"\n",
        "  elif(max_index==11):\n",
        "    real_sentiment1 = \"surprise\"\n",
        "  elif(max_index==12):\n",
        "    real_sentiment1= \"worry\"\n",
        "\n",
        "  if real_sentiment1 == \"sadness\" or real_sentiment1 == \"empty\" or real_sentiment1 == \"boredom\":\n",
        "    print(\"I am sorry you are feeling this way. Is there anything I can do to help? Would you like to continue talking about it to me or someone else?\")\n",
        "  elif real_sentiment1 == \"happiness\" or real_sentiment1 == \"enthusiasm\" or real_sentiment1 == \"love\" or real_sentiment1 == \"relief\" or real_sentiment1 ==\"fun\":\n",
        "    print(\"Wow that is so great, I am so happy for you\")\n",
        "  elif real_sentiment1 == \"hate\" or real_sentiment1 == \"anger\":\n",
        "    print(\"I am sorry you feel this way. Can you tell me more about what is making you feel this way?\")\n",
        "  elif(real_sentiment1 == \"surprise\"):\n",
        "    print(\"Why do you feel surprised?\")\n",
        "  elif(real_sentiment1 == \"worry\"):\n",
        "    print(\"I am sorry you are worried, but remember to not always worry about things you can't control to and to focus on what you can.\")\n",
        "\n",
        "  user_response4= input()\n",
        "  if user_response4 != \"bye\":\n",
        "    print(randomQuestion2)\n",
        "    user_response2= input()\n",
        "    text_sequence = tokenizer.texts_to_sequences([user_response2])\n",
        "    text_sequence = pad_sequences(text_sequence, maxlen=100)\n",
        "\n",
        "    sentiment2 = model.predict(text_sequence)\n",
        "\n",
        "\n",
        "    # Using numpy.array.argmax()\n",
        "    max_index2 = np.array(sentiment2).argmax()\n",
        "    real_sentiment2 = \"any\"\n",
        "    if(max_index2==0):\n",
        "      real_sentiment2= \"anger\"\n",
        "    elif(max_index2==1):\n",
        "      real_sentiment2= \"boredom\"\n",
        "    elif(max_index2==2):\n",
        "      real_sentiment2 = \"empty\"\n",
        "    elif(max_index2==3):\n",
        "      real_sentiment2 = \"enthusiasm\"\n",
        "    elif(max_index2==4):\n",
        "      real_sentiment2= \"fun\"\n",
        "    elif(max_index2==5):\n",
        "      real_sentiment2 = \"happiness\"\n",
        "    elif(max_index2==6):\n",
        "      real_sentiment2= \"hate\"\n",
        "    elif(max_index2==7):\n",
        "      real_sentiment2 = \"love\"\n",
        "    elif(max_index2==8):\n",
        "      real_sentiment2= \"neutral\"\n",
        "    elif(max_index2==9):\n",
        "      real_sentiment2 = \"relief\"\n",
        "    elif(max_index2==10):\n",
        "      real_sentiment2= \"sadness\"\n",
        "    elif(max_index2==11):\n",
        "      real_sentiment2 = \"surprise\"\n",
        "    elif(max_index2==12):\n",
        "      real_sentiment2= \"worry\"\n",
        "\n",
        "    if real_sentiment2 == \"sadness\" or real_sentiment2 == \"empty\" or real_sentiment2 == \"boredom\":\n",
        "      print(\"I am sorry you are feeling this way. Is there anything I can do to help? Would you like to continue talking about it to me or someone else?\")\n",
        "    elif real_sentiment2 == \"happiness\" or real_sentiment2 == \"enthusiasm\" or real_sentiment2 == \"love\" or real_sentiment2 == \"relief\" or real_sentiment2 ==\"fun\":\n",
        "      print(\"Wow that is so great, I am so happy for you\")\n",
        "    elif real_sentiment2 == \"hate\" or real_sentiment2 == \"anger\":\n",
        "      print(\"I am sorry you feel this way. Can you tell me more about what is making you feel this way?\")\n",
        "    elif(real_sentiment2 == \"surprise\"):\n",
        "      print(\"Why do you feel surprised?\")\n",
        "    elif(real_sentiment2 == \"worry\"):\n",
        "      print(\"I am sorry you are worried, but remember to not always worry about things you can't control to and to focus on what you can.\")\n",
        "\n",
        "  user_response5= input()\n",
        "  if (user_response5 != \"bye\"):\n",
        "    print(randomQuestion3)\n",
        "    user_response3 = input()\n",
        "    text_sequence = tokenizer.texts_to_sequences([user_response3])\n",
        "    text_sequence = pad_sequences(text_sequence, maxlen=100)\n",
        "\n",
        "    sentiment3 = model.predict(text_sequence)\n",
        "\n",
        "    # Using numpy.array.argmax()\n",
        "    max_index3= np.array(sentiment3).argmax()\n",
        "    real_sentiment3 = \"any\"\n",
        "\n",
        "    if(max_index3==0):\n",
        "      real_sentiment3= \"anger\"\n",
        "    elif(max_index3==1):\n",
        "      real_sentiment3= \"boredom\"\n",
        "    elif(max_index3==2):\n",
        "      real_sentiment3 = \"empty\"\n",
        "    elif(max_index3==3):\n",
        "      real_sentiment3 = \"enthusiasm\"\n",
        "    elif(max_index3==4):\n",
        "      real_sentiment3= \"fun\"\n",
        "    elif(max_index3==5):\n",
        "      real_sentiment3 = \"happiness\"\n",
        "    elif(max_index3==6):\n",
        "      real_sentiment3= \"hate\"\n",
        "    elif(max_index3==7):\n",
        "      real_sentiment3 = \"love\"\n",
        "    elif(max_index3==8):\n",
        "      real_sentiment3= \"neutral\"\n",
        "    elif(max_index3==9):\n",
        "      real_sentiment3 = \"relief\"\n",
        "    elif(max_index3==10):\n",
        "      real_sentiment3= \"sadness\"\n",
        "    elif(max_index3==11):\n",
        "      real_sentiment3 = \"surprise\"\n",
        "    elif(max_index3==12):\n",
        "      real_sentiment3= \"worry\"\n",
        "    if real_sentiment3 == \"sadness\" or real_sentiment3 == \"empty\" or real_sentiment3 == \"boredom\":\n",
        "      print(\"I am sorry you are feeling this way. Is there anything I can do to help? Would you like to continue talking about it to me or someone else?\")\n",
        "    elif real_sentiment3 == \"happiness\" or real_sentiment3 == \"enthusiasm\" or real_sentiment3 == \"love\" or real_sentiment3 == \"relief\" or real_sentiment3 ==\"fun\":\n",
        "      print(\"Wow that is so great, I am so happy for you\")\n",
        "    elif real_sentiment3 == \"hate\" or real_sentiment3 == \"anger\":\n",
        "      print(\"I am sorry you feel this way. Can you tell me more about what is making you feel this way?\")\n",
        "    elif(real_sentiment3 == \"surprise\"):\n",
        "      print(\"Why do you feel surprised?\")\n",
        "    elif(real_sentiment3 == \"worry\"):\n",
        "      print(\"I am sorry you are worried, but remember to not always worry about things you can't control to and to focus on what you can.\")\n",
        "    user_reponse6 = input()\n",
        "  flag = False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEU4AOuLMQru",
        "outputId": "bffd7b80-97df-4e7a-ea07-bb28561fcda7"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AMES: My name is AMES. I will be asking you a few questions about how you are feeling. If you want to exit, type Bye!\n",
            "How are you feeling?\n",
            "Not good\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Wow that is so great, I am so happy for you\n",
            "thanks\n",
            "How have you been?\n",
            "Not good\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Wow that is so great, I am so happy for you\n",
            "thanks\n",
            "Is something worrying you?\n",
            "Yes \n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Wow that is so great, I am so happy for you\n",
            "bye\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "L = [\"How are you feeling?\\n\", \"How have you been?\\n\", \"Is something worrying you?\\n\", \"Are you having trouble sleeping? If so, why?\\n\", \"Is there anything you want to talk about?\\n\", \"How would you like things to be different?\\n\", \"Did something upset you today?\\n\", \"Is someone bothering you?\\n\"]\n",
        "\n",
        "# writing to file\n",
        "file1 = open('Chatbot.txt', 'w')\n",
        "file1.writelines(L)\n",
        "file1.close()\n",
        "\n",
        "# Using readlines()\n",
        "file1 = open('Chatbot.txt', 'r')\n",
        "Lines = file1.readlines()\n",
        "\n",
        "count = 0\n",
        "# Strips the newline character\n",
        "for line in Lines:\n",
        "    count += 1\n",
        "    print(\"Line{}: {}\".format(count, line.strip()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RPFd-FrRs3b",
        "outputId": "78f252c9-bcb8-4210-f416-89a506b88a3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Line1: How are you feeling?\n",
            "Line2: How have you been?\n",
            "Line3: Is something worrying you?\n",
            "Line4: Are you having trouble sleeping? If so, why?\n",
            "Line5: Is there anything you want to talk about?\n",
            "Line6: How would you like things to be different?\n",
            "Line7: Did something upset you today?\n",
            "Line8: Is someone bothering you?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Convert(string):\n",
        "    li = list(string.split(\"-\"))\n",
        "    return li\n",
        "\n",
        "\n",
        "# Driver code\n",
        "str1 = \"How are you feeling?-How have you been?-Is something worrying you?-Are you having trouble sleeping? If so, why?-Is there anything you want to talk about?-How would you like things to be different?-Did something upset you today?-Is someone bothering you?\"\n",
        "print(Convert(str1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBQ1vYxJTp-Q",
        "outputId": "41ce96c5-fc9f-4c3d-9ec2-20a04cabb8cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['How are you feeling?', 'How have you been?', 'Is something worrying you?', 'Are you having trouble sleeping? If so, why?', 'Is there anything you want to talk about?', 'How would you like things to be different?', 'Did something upset you today?', 'Is someone bothering you?']\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}